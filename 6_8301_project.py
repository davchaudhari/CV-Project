# -*- coding: utf-8 -*-
"""6.8301 Project

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1a0Zaan_aIP3lc0zbOTRRcUM_O2vABzX-

# Skin Cancer Detection

## Dependencies
"""

import pandas as pd
import os
import shutil
from torchvision import datasets, models, transforms
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
import copy
import time
import torch.nn.functional as F

from google.colab import drive
drive.mount('/content/drive')

################################

data_dir = '/content/drive/MyDrive/CV project/data/ham10000-skin-cancer/'
# data_dir = '/content/drive/MyDrive/MIT-Education/Sophomore Year/CV/CV project/data/ham10000-skin-cancer/'
metadata_path = os.path.join(data_dir, 'HAM10000_metadata.csv')
images_dir = os.path.join(data_dir, 'HAM10000_images_part_1')
images_dir_2 = os.path.join(data_dir, 'HAM10000_images_part_2')

# image_files = [os.path.join(images_dir, f) for f in os.listdir(images_dir) if f.endswith('.jpg')]
# image_files += [os.path.join(images_dir_2, f) for f in os.listdir(images_dir_2) if f.endswith('.jpg')]
# print(f"Number of images: {len(image_files)}")

destination_folder = os.path.join(data_dir, 'segmentedData')
# copied_images = [os.path.join(destination_folder, f) for f in os.listdir(destination_folder) if f.endswith('.jpg')]
# print(f"Number of images: {len(copied_images)}")

saved = True

if not saved:
  if not os.path.exists(destination_folder):
      os.makedirs(destination_folder)

  for image_file in image_files:
      filename = os.path.basename(image_file)
      destination_path = os.path.join(destination_folder, filename)
      shutil.copyfile(image_file, destination_path)

  print("Images saved to", destination_folder)
  saved = True

"""## Data Analysis"""

metadata = pd.read_csv(metadata_path)

lesion_counts = metadata['dx'].value_counts()

lesion_dict = {
    'akiec': 'Actinic keratoses',
    'bcc': 'Basal cell carcinoma',
    'mel': 'Melanoma',
    'nv': 'Melanocytic nevi',
    'bkl': 'Benign keratosis-like lesions',
    'vasc': 'Vascular lesions',
    'df': 'Dermatofibroma'
}

labels = [lesion_dict[code] for code in lesion_counts.index]
sizes = lesion_counts.values


# Plotting
plt.figure(figsize=(10, 8))
wedges, texts, autotexts = plt.pie(lesion_counts, autopct='%1.1f%%', startangle=140, colors=plt.cm.Paired(range(len(lesion_counts))))
plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle
plt.title('Pie Chart of Lesion Types')
plt.legend(labels, loc="best")
plt.show()

"""### Only Run the Below Cell if New Metadata Needed"""

# Define a mapping function to convert diagnosis to malignant or benign
def label_to_category(label):
    """""
    Convert diagnosis label to malignant or benign.
    """
    if label in ['akiec', 'bcc', 'mel']:
        return 'malignant'
    elif label in ['bkl', 'df', 'nv', 'vasc']:
        return 'benign'
    else:
        return 'unknown'  # In case there are any unexpected labels

# Apply the mapping function to the 'dx' column
metadata['diagnosis'] = metadata['dx'].apply(label_to_category)
metadata['diagnosis_idx'] = pd.Categorical(metadata['diagnosis']).codes

# Drop the original 'dx' column
metadata = metadata.drop('dx', axis=1)

# Save the modified dataframe to a new CSV file
new_metadata_path = os.path.join(data_dir, 'HAM10000_new_metadata.csv')  # Update this to your desired new CSV path
metadata.to_csv(new_metadata_path, index=False)

print(f"New metadata saved to {new_metadata_path}")

"""### Continue"""

new_metadata_path = os.path.join(data_dir, 'HAM10000_new_metadata.csv')
data = pd.read_csv(new_metadata_path)

lesion_counts = data['diagnosis'].value_counts()

labels = [code for code in lesion_counts.index]
sizes = lesion_counts.values

# Plotting
plt.figure(figsize=(10, 8))
wedges, texts, autotexts = plt.pie(lesion_counts, autopct='%1.1f%%', startangle=140, colors=plt.cm.Paired(range(len(lesion_counts))))
plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle
plt.title('Pie Chart of Lesion Types')
plt.legend(labels, loc="best")
plt.show()

# Histogram by Age
plt.figure(figsize=(10, 6))
plt.hist(data['age'].dropna(), bins=30, color='forestgreen', edgecolor='black')
plt.title('Histogram of Age')
plt.xlabel('Age')
plt.ylabel('Frequency')
plt.grid(True)
plt.show()

# Histogram by Sex
plt.figure(figsize=(10, 6))
plt.hist(data['sex'].dropna(), bins=30, color='palevioletred', edgecolor='black')
plt.title('Histogram of Sex')
plt.xlabel('Sex')
plt.ylabel('Frequency')
plt.grid(True)
plt.show()

# Localization
localizations = data['localization'].value_counts()
labels = [area for area in localizations.index]
sizes = localizations.values
# Plotting
plt.figure(figsize=(10, 8))
wedges, texts, autotexts = plt.pie(localizations, autopct='%1.1f%%', startangle=140, colors=plt.cm.Paired(range(len(localizations))))
plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle
plt.title('Pie Chart of Localization Areas')
plt.legend(labels, loc="best")
plt.show()

# Histogram by Localization Area
plt.figure(figsize=(20, 12))
plt.hist(data['localization'].dropna(), bins=30, color='royalblue', edgecolor='black')
plt.title('Histogram of Localization')
plt.xlabel('Localization')
plt.ylabel('Frequency')
plt.grid(True)
plt.show()

from random import seed, shuffle

def split_data(source_dir, train_dir, val_dir, test_dir, train_size=0.7, val_size=0.15, test_size=0.15):
    """""
    Split data into train, validation, and test sets.
    """
    # Ensure the percentages sum to 1
    assert (train_size + val_size + test_size) == 1

    # Make sure the directory exists and is not empty
    files = [os.path.join(source_dir, f) for f in os.listdir(source_dir) if os.path.isfile(os.path.join(source_dir, f))]
    if not files:
        print("No files found in the directory.")
        return

    # Shuffle files to ensure random distribution
    seed(42)
    shuffle(files)

    # Calculate split indices
    train_end = int(len(files) * train_size)
    val_end = train_end + int(len(files) * val_size)

    # Split files accordingly
    train_files = files[:train_end]
    val_files = files[train_end:val_end]
    test_files = files[val_end:]

    # Function to copy files to a new directory
    def copy_files(files, directory):
        if not os.path.exists(directory):
            os.makedirs(directory)
        for f in files:
            shutil.copy(f, directory)

    # Copy files to respective directories
    copy_files(train_files, train_dir)
    copy_files(val_files, val_dir)
    copy_files(test_files, test_dir)
    print(f"Files distributed: {len(train_files)} train, {len(val_files)} val, {len(test_files)} test.")

# Paths to your directories
source_directory = destination_folder
train_directory = os.path.join(data_dir, 'HAM10000_train')
val_directory = os.path.join(data_dir, 'HAM10000_val')
test_directory = os.path.join(data_dir, 'HAM10000_test')

split = True

if not split:
  split_data(source_directory, train_directory, val_directory, test_directory)

"""## Models and Training Infra"""

def initialize_model(model_name, num_classes, resume_from = None, use_pretrained = False, pretrained_path=None):
    """
    Args:
        model_name: Name of the model to be initialized.
        num_classes: number of classes in the dataset.
        resume_from: Path to the weights to be loaded.
        use_pretrained: If True, use the pretrained model.


    Returns:
        model: The initialized model.
        input_size: The input size of the model.

    Initialize model for transfer learning.
    """
    model_ft = None
    input_size = 0

    if model_name == "resnet":
        """ Resnet18
        """
        model_ft = models.resnet18(pretrained=use_pretrained)
        num_ftrs = model_ft.fc.in_features
        model_ft.fc = nn.Linear(num_ftrs, num_classes)
        input_size = 224

    elif model_name == "resnet50":
        """ Resnet50
        """
        model_ft = models.resnet50(pretrained=use_pretrained)
        num_ftrs = model_ft.fc.in_features
        model_ft.fc = nn.Linear(num_ftrs, num_classes)
        input_size = 224

    elif model_name == "alexnet":
        """ Alexnet
        """
        model_ft = models.alexnet(pretrained=use_pretrained)
        num_ftrs = model_ft.classifier[6].in_features
        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)
        input_size = 224

    elif model_name == "vgg":
        """ VGG16
        """
        model_ft = models.vgg16(pretrained=use_pretrained)
        num_ftrs = model_ft.classifier[6].in_features
        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)
        input_size = 224

    elif model_name == "densenet":
        """ Densenet
        """
        model_ft = models.densenet121(pretrained=use_pretrained)
        num_ftrs = model_ft.classifier.in_features
        model_ft.classifier = nn.Linear(num_ftrs, num_classes)
        input_size = 224

    elif model_name == "resnet101":
        """ Resnet101
        """
        model_ft = models.resnet101(pretrained=use_pretrained)
        num_ftrs = model_ft.fc.in_features
        model_ft.fc = nn.Linear(num_ftrs, num_classes)
        input_size = 224

    elif model_name == "resnet152":
        """ Resnet152
        """
        model_ft = models.resnet152(pretrained=use_pretrained)
        num_ftrs = model_ft.fc.in_features
        model_ft.fc = nn.Linear(num_ftrs, num_classes)
        input_size = 224

    else:
        raise Exception("Invalid model name!")

    if resume_from is not None:
        print("Loading weights from %s" % resume_from)
        model_ft.load_state_dict(torch.load(resume_from))

    if pretrained_path is not None:
        model_ft.load_state_dict(torch.load(pretrained_path))

    return model_ft, input_size

from torch.utils.data import Dataset, DataLoader
from PIL import Image
import torchvision.transforms as transforms

class ImageDataset(Dataset):
    def __init__(self, dataframe, transform=None):
        """
        Args:
            dataframe (pandas.DataFrame): DataFrame containing image paths and labels.
            transform (callable, optional): Transform to be applied on a sample.
        """
        g = dataframe.groupby('diagnosis_idx')
        min_size = min(g.size())  # Find the number of images in the smallest class
        self.img_labels = g.apply(lambda x: x.sample(min_size, random_state=42)).reset_index(drop=True)
        self.transform = transform

    def __len__(self):
        """
        Returns:
            int: Number of samples in the dataset.
        """
        return len(self.img_labels)

    def __getitem__(self, idx):
        """
        Args:
            idx (int): Index of the sample to be retrieved.

        Returns:
            tuple: (image, label) where image is a PIL Image and label is an integer.
        """
        # print(f"idx is { idx }")
        img_path = self.img_labels['image_path'][idx]
        # print(f"image path is { img_path }")
        image = Image.open(img_path).convert('RGB')
        label = torch.tensor(self.img_labels['diagnosis_idx'][idx])
        # print(f"label is { label }")
        if self.transform:
            image = self.transform(image)
        return image, label

from sklearn.model_selection import train_test_split

# Define transformations
transform = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

# Directory where images are stored
img_dir = destination_folder

# Load the metadata
metadata_path = os.path.join(data_dir, 'HAM10000_new_metadata.csv')
metadata = pd.read_csv(metadata_path)
print(metadata.head())
metadata['image_path'] = metadata['image_id'].apply(lambda x: os.path.join(data_dir, "HAM10000_images_folder", x + '.jpg'))
print(metadata.head())
print(metadata.shape)

# Splitting the data (here just a simple split, replace with your actual train-test-val split logic)
train_val, test_data = train_test_split(metadata, test_size=0.15, random_state=42)
train_data, val_data = train_test_split(train_val, test_size=0.15 / 0.85, random_state=42)  # Adjust the ratio as needed

print(f"Train data shape: {train_data.shape}")
print(f"Validation data shape: {val_data.shape}")
print(f"Test data shape: {test_data.shape}")

# Create dataset instances
train_dataset = ImageDataset(train_data, transform=transform)
val_dataset = ImageDataset(val_data, transform=transform)
test_dataset = ImageDataset(test_data, transform=transform)

# Create DataLoader
from torch.utils.data import DataLoader

train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

dataloaders = {
    'train': train_loader,
    'val': val_loader,
    'test': test_loader
}

print(len(train_dataset))
print(len(val_dataset))
print(len(test_dataset))

accuracies = {}
test_accuracies = []

from torch.autograd import Variable
import tqdm

def train_model(model, dataloaders, criterion, optimizer, num_epochs=10, device='cuda'):
    """
    Args:
        model (torch.nn.Module): The model to be trained.
        dataloaders (dict): A dictionary containing the training and validation dataloaders.
        criterion (torch.nn.Module): The loss function used for training.
        optimizer (torch.optim.Optimizer): The optimizer used for training.
        num_epochs (int): The number of epochs to train for.
        device (str): The device to use for training.


    Returns:
        torch.nn.Module: The trained model.

    Description:
        Train a model using the specified dataloaders and optimizer.
    """
    model.to(device)
    best_acc = 0.0

    for epoch in range(num_epochs):
        print(f'Epoch {epoch + 1}/{num_epochs}')

        # Iterate over both training and validation phases
        for phase in ['train', 'val']:
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode

            running_loss = 0.0
            running_corrects = 0

            # Iterate over data.

            for i, (inputs, labels) in enumerate(dataloaders[phase]):
                print(f'Batch {i + 1}/{len(dataloaders[phase])}')
                inputs = Variable(inputs).to(device)
                labels = Variable(labels).to(device)

                # Zero the parameter gradients
                optimizer.zero_grad()

                # Forward
                # Track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)
                    loss = criterion(outputs, labels)
                    _, preds = torch.max(outputs, 1)  # Get the predictions

                    # Backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()

                # Statistics
                running_loss += loss.item() * inputs.size(0)
                running_corrects += torch.sum(preds == labels.data)

            epoch_loss = running_loss / len(dataloaders[phase].dataset)
            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)

            print(f'{phase.capitalize()} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')

            # Deep copy the model if we got a better accuracy in validation phase
            if phase == 'val' and epoch_acc > best_acc:
                best_acc = epoch_acc
                best_model_wts = copy.deepcopy(model.state_dict())

    # Load best model weights
    model.load_state_dict(best_model_wts)
    return model

def evaluate_model(model, dataloader, device='cuda'):
    model.eval()  # Set the model to evaluation mode
    all_preds = []
    all_labels = []
    inputs_list = []
    outputs_list = []

    with torch.no_grad():
        for inputs, labels in dataloader:
            inputs = inputs.to(device)
            labels = labels.to(device)

            outputs = model(inputs)
            _, preds = torch.max(outputs, 1)

            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())
            inputs_list.extend(inputs.cpu().numpy())
            outputs_list.extend(outputs.cpu().numpy())


    return inputs_list, outputs_list, all_labels, all_preds

"""## ResNet"""

# Setup
images_dir = os.path.join(data_dir, 'segmentedData')  # Path to the directory containing images
batch_size = 32
model_name = 'resnet'
num_classes = 2  # Set this to the number of your classes

# Initialize model
model, input_size = initialize_model(model_name, num_classes, use_pretrained=True)
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)

# Train the model
model_resnet = train_model(model, dataloaders, criterion, optimizer, num_epochs=25)

from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
import seaborn as sns
import matplotlib.pyplot as plt

# model, input_size = initialize_model("resnet", num_classes, use_pretrained=True)
# model.load_state_dict(torch.load('/content/drive/MyDrive/MIT-Education/Sophomore Year/CV/CV project/weights/data imbalance/resnet_model_weights.txt'))

model = model_resnet
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)
# Assuming you have the test_loader set up
inputs, outputs, labels, preds = evaluate_model(model, dataloaders['test'], device)

# Calculate accuracy
accuracy = accuracy_score(labels, preds)
print(f'Test Accuracy: {accuracy:.4f}')
accuracies["resnet"] = accuracy

# Generate a classification report
report = classification_report(labels, preds, target_names=['Benign', 'Malignant'], output_dict=True)
print(classification_report(labels, preds, target_names=['Benign', 'Malignant']))

# Confusion Matrix
conf_matrix = confusion_matrix(labels, preds)
plt.figure(figsize=(4, 3))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Benign', 'Malignant'], yticklabels=['Benign', 'Malignant'])
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('ResNet Confusion Matrix')
plt.show()

# Set up threshold values
thresholds = np.linspace(0, 1, 1000)
pairs = []

# Calculate TP, FP, TN, FN at each threshold
for threshold in thresholds:
    TP = FP = FN = TN = 0
    for true_label, output in zip(labels, outputs):
        prob = torch.nn.functional.softmax(torch.tensor(output), dim=0)[1]  # Convert logits to probabilities for class 1
        if prob >= threshold:
            if true_label == 1:
                TP += 1
            else:
                FP += 1
        else:
            if true_label == 1:
                FN += 1
            else:
                TN += 1

    precision = 1 if TP + FP == 0 else TP / (TP + FP)
    recall = 0 if TP + FN == 0 else TP / (TP + FN)
    pairs.append((recall, precision))

# Sorting by recall to ensure proper AUC calculation
pairs.sort(key=lambda x: x[0])
recallL, precisionL = zip(*pairs)

# Calculate AUC using the trapezoidal rule
auc_value = np.trapz(precisionL, recallL)

# Plotting
plt.figure(figsize=(4, 3))
plt.plot(recallL, precisionL, label=f'Precision-Recall Curve')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title(f'ResNet Precision-Recall Curve (AUC = {auc_value:.2f})')
plt.legend()
plt.show()

print(f"The AUC is {auc_value:.2f}.")

# Saving the model
weight_dir = '/content/drive/MyDrive/MIT-Education/Sophomore Year/CV/CV project/weights/segment'
torch.save(model.state_dict(), os.path.join(weight_dir, 'resnet_model_weights.txt'))

# To load the model
model.load_state_dict(torch.load(os.path.join(weight_dir, 'resnet_model_weights.txt')))
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

"""## AlexNet"""

# Setup
images_dir = os.path.join(data_dir, 'segmentedData')  # Path to the directory containing images
batch_size = 32
model_name = 'alexnet'
num_classes = 2  # Set this to the number of your classes

# Initialize model
model_alexnet, input_size = initialize_model(model_name, num_classes, use_pretrained=True)
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(model_alexnet.parameters(), lr=0.001, momentum=0.9)

# Train the model
model_alexnet = train_model(model_alexnet, dataloaders, criterion, optimizer, num_epochs=25)

# model, input_size = initialize_model("alexnet", num_classes, use_pretrained=True)
# model.load_state_dict(torch.load('/content/drive/MyDrive/MIT-Education/Sophomore Year/CV/CV project/weights/data imbalance/alexnet_model_weights.txt'))
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
import seaborn as sns
import matplotlib.pyplot as plt

model_alexnet, input_size = initialize_model("alexnet", 2, use_pretrained=True, pretrained_path=os.path.join('/content/drive/MyDrive/MIT-Education/Sophomore Year/CV/CV project/weights/segment', 'alexnet_model_weights.txt'))
model = model_alexnet
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)
# Assuming you have the test_loader set up
inputs, outputs, labels, preds = evaluate_model(model, dataloaders['test'], device)

# Calculate accuracy
accuracy = accuracy_score(labels, preds)
print(f'Test Accuracy: {accuracy:.4f}')
accuracies["alexnet"] = accuracy

# Generate a classification report
report = classification_report(labels, preds, target_names=['Benign', 'Malignant'], output_dict=True)
print(classification_report(labels, preds, target_names=['Benign', 'Malignant']))

# Confusion Matrix
conf_matrix = confusion_matrix(labels, preds)
plt.figure(figsize=(4, 3))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Benign', 'Malignant'], yticklabels=['Benign', 'Malignant'])
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('AlexNet Confusion Matrix')
plt.show()

# Set up threshold values
thresholds = np.linspace(0, 1, 1000)
pairs = []

# Calculate TP, FP, TN, FN at each threshold
for threshold in thresholds:
    TP = FP = FN = TN = 0
    for true_label, output in zip(labels, outputs):
        prob = torch.nn.functional.softmax(torch.tensor(output), dim=0)[1]  # Convert logits to probabilities for class 1
        if prob >= threshold:
            if true_label == 1:
                TP += 1
            else:
                FP += 1
        else:
            if true_label == 1:
                FN += 1
            else:
                TN += 1

    precision = 1 if TP + FP == 0 else TP / (TP + FP)
    recall = 0 if TP + FN == 0 else TP / (TP + FN)
    pairs.append((recall, precision))

# Sorting by recall to ensure proper AUC calculation
pairs.sort(key=lambda x: x[0])
recallL, precisionL = zip(*pairs)

# Calculate AUC using the trapezoidal rule
auc_value = np.trapz(precisionL, recallL)

# Plotting
plt.figure(figsize=(4,3))
plt.plot(recallL, precisionL, label=f'Precision-Recall Curve')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title(f'AlexNet Precision-Recall Curve (AUC = {auc_value:.2f})')
plt.legend()
plt.show()

print(f"The AUC is {auc_value:.2f}.")

# Saving the model
weight_dir = '/content/drive/MyDrive/MIT-Education/Sophomore Year/CV/CV project/weights/segment'
torch.save(model_alexnet.state_dict(), os.path.join(weight_dir, 'alexnet_model_weights.txt'))

# To load the model
model_alexnet.load_state_dict(torch.load(os.path.join(weight_dir, 'alexnet_model_weights.txt')))
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model_alexnet.to(device)

"""## VGG"""

# Setup
images_dir = os.path.join(data_dir, 'segmentedData')  # Path to the directory containing images
batch_size = 32
model_name = 'vgg'
num_classes = 2  # Set this to the number of your classes

# Initialize model
vgg_model, input_size = initialize_model(model_name, num_classes, use_pretrained=True)
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(vgg_model.parameters(), lr=0.001, momentum=0.9)

# Train the model
model_vgg = train_model(vgg_model, dataloaders, criterion, optimizer, num_epochs=25)

# model, input_size = initialize_model("vgg", num_classes, use_pretrained=True)
# model.load_state_dict(torch.load(os.path.join(data_dir, 'weights/nosegment/vgg_model_weights.txt')))
model_vgg, input_size = initialize_model("vgg", 2, use_pretrained=True, pretrained_path=os.path.join('/content/drive/MyDrive/MIT-Education/Sophomore Year/CV/CV project/weights/segment', 'vgg_model_weights.txt'))
model = model_vgg
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)
# Assuming you have the test_loader set up
inputs, outputs, labels, preds = evaluate_model(model, dataloaders['test'], device)

# Calculate accuracy
accuracy = accuracy_score(labels, preds)
print(f'Test Accuracy: {accuracy:.4f}')
accuracies["vgg"] = accuracy

# Generate a classification report
report = classification_report(labels, preds, target_names=['Benign', 'Malignant'], output_dict=True)
print(classification_report(labels, preds, target_names=['Benign', 'Malignant']))

# Confusion Matrix
conf_matrix = confusion_matrix(labels, preds)
plt.figure(figsize=(4, 3))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Benign', 'Malignant'], yticklabels=['Benign', 'Malignant'])
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('VGG Confusion Matrix')
plt.show()

from sklearn.metrics import auc

# Set up threshold values
thresholds = np.linspace(0, 1, 1000)
pairs = []

# Calculate TP, FP, TN, FN at each threshold
for threshold in thresholds:
    TP = FP = FN = TN = 0
    for true_label, output in zip(labels, outputs):
        prob = torch.nn.functional.softmax(torch.tensor(output), dim=0)[1]  # Convert logits to probabilities for class 1
        if prob >= threshold:
            if true_label == 1:
                TP += 1
            else:
                FP += 1
        else:
            if true_label == 1:
                FN += 1
            else:
                TN += 1

    precision = 1 if TP + FP == 0 else TP / (TP + FP)
    recall = 0 if TP + FN == 0 else TP / (TP + FN)
    pairs.append((recall, precision))

# Sorting by recall to ensure proper AUC calculation
pairs.sort(key=lambda x: x[0])
recallL, precisionL = zip(*pairs)

# Calculate AUC using the trapezoidal rule
auc_value = auc(recallL, precisionL)

# Plotting
plt.figure(figsize=(4, 3))
plt.plot(recallL, precisionL, label=f'Precision-Recall Curve')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title(f'VGG Precision-Recall Curve (AUC = {auc_value:.2f})')
plt.legend()
plt.show()

print(f"The AUC is {auc_value:.2f}.")

# Saving the model
weight_dir = '/content/drive/MyDrive/MIT-Education/Sophomore Year/CV/CV project/weights/segment'
torch.save(model.state_dict(), os.path.join(weight_dir, 'vgg_model_weights.txt'))

# To load the model
model.load_state_dict(torch.load(os.path.join(weight_dir, 'vgg_model_weights.txt')))
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

"""## DenseNet"""

# Setup
images_dir = os.path.join(data_dir, 'segmentedData')  # Path to the directory containing images
batch_size = 32
model_name = 'densenet'
num_classes = 2  # Set this to the number of your classes

# Initialize model
dense_model, input_size = initialize_model(model_name, num_classes, use_pretrained=True)
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(dense_model.parameters(), lr=0.001, momentum=0.9)

# Train the model
model_densenet = train_model(dense_model, dataloaders, criterion, optimizer, num_epochs=25)

# model, input_size = initialize_model("densenet", num_classes, use_pretrained=True)
# model.load_state_dict(torch.load('/content/drive/MyDrive/MIT-Education/Sophomore Year/CV/CV project/weights/nosegment/densenet_model_weights.txt'))

model_densenet, input_size = initialize_model("densenet", 2, use_pretrained=True, pretrained_path=os.path.join('/content/drive/MyDrive/MIT-Education/Sophomore Year/CV/CV project/weights/segment', 'densenet_model_weights.txt'))
model = model_densenet
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)
# Assuming you have the test_loader set up
inputs, outputs, labels, preds = evaluate_model(model, dataloaders['test'], device)

# Calculate accuracy
accuracy = accuracy_score(labels, preds)
print(f'Test Accuracy: {accuracy:.4f}')
accuracies["densenet"] = accuracy

# Generate a classification report
report = classification_report(labels, preds, target_names=['Benign', 'Malignant'], output_dict=True)
print(classification_report(labels, preds, target_names=['Benign', 'Malignant']))

# Confusion Matrix
conf_matrix = confusion_matrix(labels, preds)
plt.figure(figsize=(4, 3))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Benign', 'Malignant'], yticklabels=['Benign', 'Malignant'])
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('DenseNet Confusion Matrix')
plt.show()

from sklearn.metrics import auc

# Set up threshold values
thresholds = np.linspace(0, 1, 1000)
pairs = []

# Calculate TP, FP, TN, FN at each threshold
for threshold in thresholds:
    TP = FP = FN = TN = 0
    for true_label, output in zip(labels, outputs):
        prob = torch.nn.functional.softmax(torch.tensor(output), dim=0)[1]  # Convert logits to probabilities for class 1
        if prob >= threshold:
            if true_label == 1:
                TP += 1
            else:
                FP += 1
        else:
            if true_label == 1:
                FN += 1
            else:
                TN += 1

    precision = 1 if TP + FP == 0 else TP / (TP + FP)
    recall = 0 if TP + FN == 0 else TP / (TP + FN)
    pairs.append((recall, precision))

# Sorting by recall to ensure proper AUC calculation
pairs.sort(key=lambda x: x[0])
recallL, precisionL = zip(*pairs)

# Extend the recall and precision arrays
extended_recalls = np.insert(recallL, 0, 0.0)  # Insert 0 at the start of the recall array
extended_precisions = np.insert(precisionL, 0, precisionL[0])  # Extend precision horizontally

# Calculate AUC
auc_value = auc(extended_recalls, extended_precisions)

# Plotting
plt.figure(figsize=(4, 3))
plt.plot(extended_recalls, extended_precisions, label=f'Precision-Recall Curve')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title(f'DenseNet Precision-Recall Curve (AUC = {auc_value:.2f})')
plt.legend()
plt.show()

print(f"The AUC is {auc_value:.2f}.")

# Saving the model
weight_dir = '/content/drive/MyDrive/MIT-Education/Sophomore Year/CV/CV project/weights/segment'
torch.save(model.state_dict(), os.path.join(weight_dir, 'densenet_model_weights.txt'))

# To load the model
model.load_state_dict(torch.load(os.path.join(weight_dir, 'densenet_model_weights.txt')))
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

"""## Ensemble"""

import numpy as np
import torch
from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_curve, auc
import matplotlib.pyplot as plt
import seaborn as sns

def ensemble_predict(models, dataloaders, weights, device, threshold=0.5):
    ensemble_scores = np.zeros(len(dataloaders['test'].dataset))
    total_weights = sum(weights)

    for i, model in enumerate(models):
        model.to(device)  # Change 'model' to 'models[i]'
        model.eval()
        predictions = []

        with torch.no_grad():
            for inputs, _ in dataloaders['test']:
                inputs = inputs.to(device)
                outputs = model(inputs)
                preds = torch.max(outputs, 1)[1]
                predictions.extend(preds.cpu().numpy())

        weighted_predictions = np.array(predictions) * weights[i]
        ensemble_scores += weighted_predictions

    # Normalize the scores by the total weights and apply threshold
    ensemble_scores /= total_weights
    ensemble_predictions = (ensemble_scores >= threshold).astype(int)
    return ensemble_predictions


def get_true_labels(dataloader):
    """ Collect all labels from the dataloader for comparison with predictions. """
    true_labels = []
    for _, labels in dataloader:
        true_labels.extend(labels.numpy())
    return np.array(true_labels)

def evaluate_ensemble(models, dataloaders, weights, device='cuda', threshold=0.5):
    true_labels = get_true_labels(dataloaders['test'])
    preds = ensemble_predict(models, dataloaders, weights, device, threshold)

    accuracy = accuracy_score(true_labels, preds)
    print(f'Ensemble Test Accuracy: {accuracy:.4f}')

    conf_matrix = confusion_matrix(true_labels, preds)
    plt.figure(figsize=(4, 3))
    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Malignant', 'Benign'], yticklabels=['Malignant', 'Benign'])
    plt.xlabel('Predicted')
    plt.ylabel('True')
    plt.title('Confusion Matrix of Ensemble')
    plt.show()

    precision, recall, _ = precision_recall_curve(true_labels, preds)
    pr_auc = auc(recall, precision)

    plt.figure(figsize=(4, 3))
    plt.plot(recall, precision, label=f'Precision-Recall Curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title(f'Precision-Recall Curve of Ensemble (AUC = {pr_auc:.2f})')
    plt.legend()
    plt.show()

# List of models
# accuracies = {}
# accuracies["resnet"] = 0.8276
# accuracies["alexnet"] = 0.8190
# accuracies["vgg"] = 0.8534
# accuracies["densenet"] = 0.8310
weight_dir = '/content/drive/MyDrive/MIT-Education/Sophomore Year/CV/CV project/weights/segment'
model_resnet, input_size = initialize_model("resnet", 2, use_pretrained=True, pretrained_path=os.path.join(weight_dir, 'resnet_model_weights.txt'))
model_alexnet, input_size = initialize_model("alexnet", 2, use_pretrained=True, pretrained_path=os.path.join(weight_dir, 'alexnet_model_weights.txt'))
model_vgg, input_size = initialize_model("vgg", 2, use_pretrained=True, pretrained_path=os.path.join(weight_dir, 'vgg_model_weights.txt'))
model_densenet, input_size = initialize_model("densenet", 2, use_pretrained=True, pretrained_path=os.path.join(weight_dir, 'densenet_model_weights.txt'))
models_list = [model_resnet, model_alexnet, model_vgg, model_densenet]  # Replace with your actual models
weights = [accuracies['resnet'], accuracies['alexnet'], accuracies['vgg'], accuracies['densenet']]  # Replace with your weights

# Call the evaluation
evaluate_ensemble(models_list, dataloaders, weights)



"""## ResNet 152"""

# Setup
images_dir = os.path.join(data_dir, 'segmetedData')  # Path to the directory containing images
batch_size = 32
model_name = 'resnet152'
num_classes = 2  # Set this to the number of your classes

# Initialize model
resnet152_model, input_size = initialize_model(model_name, num_classes, use_pretrained=True)
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(resnet152_model.parameters(), lr=0.001, momentum=0.9)

# Train the model
model_resnet152 = train_model(resnet152_model, dataloaders, criterion, optimizer, num_epochs=25)

from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
import matplotlib.pyplot as plt
import seaborn as sns

model_resnet152, input_size = initialize_model("resnet152", 2, use_pretrained=True, pretrained_path='/content/drive/MyDrive/CV project/weights/segment/resnet_152_model_weights.txt')

model = model_resnet152
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)
# Assuming you have the test_loader set up
inputs, outputs, labels, preds = evaluate_model(model, dataloaders['test'], device)

# Calculate accuracy
accuracy = accuracy_score(labels, preds)
print(f'Test Accuracy: {accuracy:.4f}')
accuracies["resnet"] = accuracy

# Generate a classification report
report = classification_report(labels, preds, target_names=['Benign', 'Malignant'], output_dict=True)
print(classification_report(labels, preds, target_names=['Benign', 'Malignant']))

# Confusion Matrix
conf_matrix = confusion_matrix(labels, preds)
plt.figure(figsize=(4, 3))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Benign', 'Malignant'], yticklabels=['Benign', 'Malignant'])
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('ResNet 152 Confusion Matrix')
plt.show()

from sklearn.metrics import precision_recall_curve, auc
import matplotlib.pyplot as plt
# Set up threshold values
thresholds = np.linspace(0, 1, 1000)
pairs = []

# Calculate TP, FP, TN, FN at each threshold
for threshold in thresholds:
    TP = FP = FN = TN = 0
    for true_label, output in zip(labels, outputs):
        prob = torch.nn.functional.softmax(torch.tensor(output), dim=0)[1]  # Convert logits to probabilities for class 1
        if prob >= threshold:
            if true_label == 1:
                TP += 1
            else:
                FP += 1
        else:
            if true_label == 1:
                FN += 1
            else:
                TN += 1

    precision = 1 if TP + FP == 0 else TP / (TP + FP)
    recall = 0 if TP + FN == 0 else TP / (TP + FN)
    pairs.append((recall, precision))

# Sorting by recall to ensure proper AUC calculation
pairs.sort(key=lambda x: x[0])
recallL, precisionL = zip(*pairs)
# Extend the recall and precision arrays
extended_recalls = np.insert(recallL, 0, 0.0)  # Insert 0 at the start of the recall array
extended_precisions = np.insert(precisionL, 0, precisionL[0])  # Extend precision horizontally

# Calculate AUC
auc_value = auc(extended_recalls, extended_precisions)

# Calculate AUC using the trapezoidal rule
# auc_value = np.trapz(precisionL, recallL)

# Plotting
plt.figure(figsize=(4, 3))
plt.plot(extended_recalls, extended_precisions, label=f'Precision-Recall Curve')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title(f'ResNet 152 Precision-Recall Curve (AUC = {auc_value:.2f})')
plt.legend()
plt.show()

print(f"The AUC is {auc_value:.2f}.")

# Saving the model
weight_dir = '/content/drive/MyDrive/CV project/weights/segment'
torch.save(model.state_dict(), os.path.join(weight_dir, 'resnet_152_model_weights.txt'))

# To load the model
model.load_state_dict(torch.load(os.path.join(weight_dir, 'resnet_152_model_weights.txt')))
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)